{
  "0\nInternational Software Testing Qualifications Board\nProvided by\nAlliance for Qualification": [],
  "0 Page ": [],
  "01 Release for GA\nv": [],
  "2\nRevision History ": [],
  "3\nTable of Contents ": [],
  "4\nAcknowledgements ": [],
  "0 Introduction ": [],
  "1 Purpose of this Syllabus ": [],
  "2 The Certified Tester AI Testing ": [],
  "3 Examinable Learning Objectives and Cognitive Level of Knowledge ": [],
  "4 Hands": [],
  "5 The Certified Tester AI Testing Exam ": [],
  "6 Accreditation ": [],
  "7 Level of Detail ": [],
  "8 How this Syllabus is Organized ": [],
  "1 Introduction to AI ": [],
  "1 Definition of AI and AI Effect ": [],
  "2 Narrow": [],
  "3 AI": [],
  "4 AI Technologies ": [],
  "5 AI Development Frameworks ": [],
  "6 Hardware for AI": [],
  "7 AI as a Service ": [],
  "1 Contracts for AI as a Service": [],
  "2 AIaaS Examples ": [],
  "8 Pre": [],
  "1 Introduction to Pre": [],
  "2 Transfer Learning ": [],
  "3 Risks of using Pre": [],
  "9 Standards": [],
  "2 Quality Characteristics for AI": [],
  "1 Flexibility and Adaptability ": [],
  "2 Autonomy ": [],
  "3 Evolution ": [],
  "4 Bias ": [],
  "5 Ethics ": [],
  "6 Side Effects and Reward Hacking ": [],
  "7 Transparency": [],
  "8 Safety and AI ": [],
  "3 Machine Learning ": [],
  "1 Forms of ML ": [],
  "1 Supervised Learning ": [],
  "2 Unsupervised Learning ": [],
  "3 Reinforcement Learning ": [],
  "2 ML Workflow ": [],
  "3 Selecting a Form of ML ": [],
  "4 Factors Involved in ML Algorithm Selection ": [],
  "5 Overfitting and Underfitting ": [],
  "1 Overfitting ": [],
  "2 Underfitting ": [],
  "3 Hands": [],
  "4 ML ": [],
  "1 Data Preparation as Part of the ML Workflow ": [],
  "1 Challenges in Data Preparation ": [],
  "2 Hands": [],
  "2 Training": [],
  "1 Hands": [],
  "3 Dataset Quality Issues ": [],
  "4 Data Quality and its Effect on the ML Model ": [],
  "5 Data Labelling for Supervised Learning ": [],
  "1 Approaches to Data Labelling ": [],
  "2 Mislabeled Data in Datasets ": [],
  "5 ML Functional Performance Metrics ": [],
  "1 Confusion Matrix ": [],
  "2 Additional ML Functional Performance Metrics for Classification": [],
  "3 Limitations of ML Functional Performance Metrics ": [],
  "4 Selecting ML Functional Performance Metrics ": [],
  "5 Benchmark Suites for ML ": [],
  "6 ML ": [],
  "1 Neural Networks ": [],
  "2 Coverage Measures for Neural Networks ": [],
  "7 Testing AI": [],
  "1 Specification of AI": [],
  "2 Test Levels for AI": [],
  "1 Input Data Testing ": [],
  "2 ML Model Testing ": [],
  "3 Component Testing ": [],
  "4 Component Integration Testing ": [],
  "5 System Testing ": [],
  "6 Acceptance Testing ": [],
  "3 Test Data for Testing AI": [],
  "4 Testing for Automation Bias in AI": [],
  "5 Documenting an AI Component ": [],
  "6 Testing for Concept Drift ": [],
  "7 Selecting a Test Approach for an ML System ": [],
  "8 Testing AI": [],
  "1 Challenges Testing Self": [],
  "2 Testing Autonomous AI": [],
  "3 Testing for Algorithmic": [],
  "4 Challenges Testing Probabilistic and Non": [],
  "5 Challenges Testing Complex AI": [],
  "6 Testing the Transparency": [],
  "7 Test Oracles for AI": [],
  "8 Test Objectives and Acceptance Criteria ": [],
  "9 Methods and Techniques for the Testing of AI": [],
  "1 Adversarial Attacks and Data Poisoning ": [],
  "1 Adversarial Attacks ": [],
  "2 Data Poisoning ": [],
  "2 Pairwise Testing ": [],
  "3 Back": [],
  "5 Metamorphic Testing ": [],
  "6 Experience": [],
  "7 Selecting Test Techniques for AI": [],
  "10 Test Environments for AI": [],
  "1 Test Environments for AI": [],
  "2 Virtual Test Environments for Testing AI": [],
  "11 Using AI for Testing ": [],
  "1 AI Technologies for Testing ": [],
  "2 Using AI to Analyze Reported Defects ": [],
  "3 Using AI for Test Case Generation ": [],
  "4 Using AI for the Optimization of Regression Test Suites ": [],
  "5 Using AI for Defect Prediction ": [],
  "6 Using AI for Testing User Interfaces ": [],
  "1 Using AI to Test Through the Graphical User Interface ": [],
  "2 Using AI to Test the GUI ": [],
  "12 References ": [],
  "1 Standards ": [],
  "2 ISTQB": [],
  "3 Books and Articles ": [],
  "4 Other References ": [],
  "13 Appendix A ": [],
  "14 Appendix B ": [],
  "15 Index ": [],
  "2021.\nIt was produced by a team from the International Software Testing Qualifications Board": [],
  "0 Introduction\n": [],
  "1 Purpose of this Syllabus\nThis syllabus forms the basis for the ISTQB": [],
  "1. To member boards": [],
  "2. To certification bodies": [],
  "3. To training providers": [],
  "4. To certification candidates": [],
  "5. To the international software and systems engineering community": [],
  "2 The Certified Tester AI Testing\nThe Certified Tester AI Testing is aimed at anyone involved in testing AI": [],
  "3 Examinable Learning Objectives and Cognitive Level of\nKnowledge\nLearning objectives support the business outcomes and are used to create the Certified Tester AI\nTesting exams": [],
  "5 The Certified Tester AI Testing Exam\nThe Certified Tester AI Testing exam will be based on this syllabus": [],
  "6 Accreditation\nAn ISTQB": [],
  "7 Level of Detail\nThe level of detail in this syllabus allows internationally consistent courses and exams": [],
  "8 How this Syllabus is Organized\nThere are eleven chapters with examinable content": [],
  "1 Definition of AI and AI Effect\nAI": [],
  "2 Describe the AI effect and how it influences the definition of AI": [],
  "2 Distinguish between narrow AI": [],
  "2 Differentiate between AI": [],
  "4 AI Technologies\nAI": [],
  "1 Recognize the different technologies used to implement AI": [],
  "5 AI Development Frameworks\nAI": [],
  "1 Identify popular AI development frameworks": [],
  "2 Compare the choices available for hardware to implement AI": [],
  "2 Explain the concept of AI as a Service ": [],
  "2 Explain the use of pre": [],
  "2 Describe how standards apply to AI": [],
  "1 Definition of AI and AI Effect\nThe term artificial intelligence ": [],
  "4 AI Technologies\nAI can be implemented using a wide range of technologies ": [],
  "5 AI Development Frameworks\nThere are many AI development frameworks available": [],
  "1 Contracts for AI as a Service\nThese AI services are typically provided with similar contracts as for non": [],
  "2 AIaaS Examples\nThe following are examples of AIaaS ": [],
  "2 Transfer Learning\nIt is also possible to take a pre": [],
  "2017. In addition": [],
  "26262. Standards in isolation are voluntary\ndocuments": [],
  "1 Flexibility and Adaptability\nAI": [],
  "2 Explain the importance of flexibility and adaptability as characteristics of AI": [],
  "2 Autonomy\nAI": [],
  "2 Explain the relationship between autonomy and AI": [],
  "3 Evolution\nAI": [],
  "2 Explain the importance of managing evolution for AI": [],
  "4 Bias\nAI": [],
  "2 Describe the different causes and types of bias found in AI": [],
  "5 Ethics\nAI": [],
  "2 Discuss the ethical principles that should be respected in the development": [],
  "6 Side Effects and Reward Hacking\nAI": [],
  "2 Explain the occurrence of side effects and reward hacking in AI": [],
  "2 Explain how transparency": [],
  "8 Safety and AI\nAI": [],
  "1 Recall the characteristics that make it difficult to use AI": [],
  "1 Flexibility and Adaptability\nFlexibility and adaptability are closely related quality characteristics": [],
  "2 Autonomy\nWhen defining autonomy": [],
  "3 Evolution\nIn this syllabus": [],
  "4 Bias\nIn the context of AI": [],
  "5 Ethics\nEthics is defined in the Cambridge Dictionary as": [],
  "6 Side Effects and Reward Hacking\nSide effects and reward hacking can result in AI": [],
  "8 Safety and AI\nIn this syllabus": [],
  "1 Forms of ML\nAI": [],
  "2 Describe classification and regression as part of supervised learning": [],
  "2 Describe clustering and association as part of unsupervised learning": [],
  "2 Describe reinforcement learning": [],
  "2 ML Workflow\nAI": [],
  "2 Summarize the workflow used to create an ML system": [],
  "3 Selecting a Form of ML\nAI": [],
  "3 Given a project scenario": [],
  "4 Factors involved in ML Algorithm Selection\nAI": [],
  "2 Explain the factors involved in the selection of ML algorithms": [],
  "5 Overfitting and Underfitting\nAI": [],
  "2 Summarize the concepts of underfitting and overfitting": [],
  "0 Demonstrate underfitting and overfitting": [],
  "1 Forms of ML\nML algorithms can be categorized as": [],
  "1 Supervised Learning\nIn this kind of learning": [],
  "2 Unsupervised Learning\nIn this kind of learning": [],
  "3 Reinforcement Learning\nReinforcement learning is an approach where the system ": [],
  "2 ML Workflow\nThe activities in the machine learning workflow are": [],
  "1. For example": [],
  "1.\nTest the Model\nOnce a model has been generated": [],
  "3 Selecting a Form of ML\nWhen selecting an appropriate ML approach": [],
  "4 Factors Involved in ML Algorithm Selection\nThere is no definitive approach to selecting the optimal ML algorithm": [],
  "5 Overfitting and Underfitting\n": [],
  "1 Overfitting\nOverfitting occurs when the model fits too closely to a set of data points and fails to properly\ngeneralize": [],
  "2 Underfitting\nUnderfitting occurs when the model is not sophisticated enough to accurately fit to the patterns in the\ntraining data": [],
  "1 Data Preparation as part of the ML Workflow\nAI": [],
  "2 Describe the activities and challenges related to data preparation": [],
  "2 Perform data preparation in support of the creation of an ML model": [],
  "2 Contrast the use of training": [],
  "2 Identify training and test datasets and create an ML model": [],
  "3 Dataset Quality Issues\nAI": [],
  "2 Describe typical dataset quality issues": [],
  "4 Data quality and its effect on the ML model\nAI": [],
  "2 Recognize how poor data quality can cause problems with the resultant ML model": [],
  "5 Data Labelling for Supervised Learning\nAI": [],
  "1 Recall the different approaches to the labelling of data in datasets for supervised\nlearning": [],
  "1 Recall reasons for the data in datasets being mislabeled": [],
  "1 Data Preparation as Part of the ML Workflow\nData preparation uses an average of ": [],
  "5.\nThe acquired data can be in various forms ": [],
  "1 Challenges in Data Preparation\nSome of the challenges related to data preparation include": [],
  "3 Dataset Quality Issues\nTypical quality issues relating to the data in a dataset include": [],
  "4 Data Quality and its Effect on the ML Model\nThe quality of the ML model is highly dependent on the quality of the dataset from which it is created": [],
  "5 Data Labelling for Supervised Learning\nData labelling is the enrichment of unlabeled ": [],
  "1 Approaches to Data Labelling\nLabelling may be performed in a number of ways": [],
  "2 Mislabeled Data in Datasets\nSupervised learning assumes that the data is correctly labeled by the data annotators": [],
  "1 Confusion Matrix\nAI": [],
  "3 Calculate the ML functional performance metrics from a given set of confusion matrix\ndata": [],
  "2 Contrast and compare the concepts behind the ML functional performance metrics for\nclassification": [],
  "3 Limitations of ML Functional Performance Metrics\nAI": [],
  "2 Summarize the limitations of using ML functional performance metrics to determine\nthe quality of the ML system": [],
  "4 Selecting ML Functional Performance Metrics\nAI": [],
  "4 Select appropriate ML functional performance metrics and": [],
  "2 Evaluate the created ML model using selected ML functional performance metrics\n": [],
  "5 Benchmark Suites for ML\nAI": [],
  "2 Explain the use of benchmark suites in the context of ML\nv": [],
  "1 Confusion Matrix\nIn a classification problem": [],
  "3 Limitations of ML Functional Performance Metrics\nML functional performance metrics are limited to measuring the functionality of the model": [],
  "4 Selecting ML Functional Performance Metrics\nIt is not normally possible to build an ML model that achieves the highest score for all of the ML\nfunctional performance metrics generated from a confusion matrix": [],
  "2. These may be\napplicable for given ML problems": [],
  "5 Benchmark Suites for ML\nNew AI technologies such as new datasets": [],
  "1 Neural Networks\nAI": [],
  "2 Explain the structure and function of a neural network including a DNN": [],
  "1 Experience the implementation of a perceptron": [],
  "2 Coverage Measures for Neural Networks\nAI": [],
  "2 Describe the different coverage measures for neural networks": [],
  "1 Neural Networks\nArtificial neural networks were initially intended to mimic the functioning of the human brain": [],
  "3 Structure of a deep neural network\nA deep neural network comprises three types of layers": [],
  "4 Computation performed by each neuron\nAs shown in Figure ": [],
  "2 Coverage Measures for Neural Networks\nAchieving white": [],
  "2 Explain how system specifications for AI": [],
  "2 Describe how AI": [],
  "1 Recall those factors associated with test data that can make testing AI": [],
  "2 Explain automation bias and how this affects testing": [],
  "5 Documenting an ML Model\nAI": [],
  "2 Describe the documentation of an AI component and understand how documentation\nsupports the testing of AI": [],
  "6 Testing for Concept Drift\nAI": [],
  "2 Explain the need for frequently testing the trained model to handle concept drift": [],
  "7 Selecting a Test Approach for an ML System\nAI": [],
  "4 For a given scenario determine a test approach to be followed when developing an\nML system": [],
  "1 Input Data Testing\nThe objective of input data testing is to ensure that the data used by the system for training and\nprediction is of the highest quality ": [],
  "2 ML Model Testing\nThe objective of ML model testing is to ensure that the selected model meets any performance criteria\nthat may have been specified": [],
  "3 Component Testing\nComponent testing is a conventional test level which is applicable to any non": [],
  "4 Component Integration Testing\nComponent integration testing is a conventional test level which is conducted to ensure that the\nsystem components ": [],
  "5 System Testing\nSystem testing is a conventional test level which is conducted to ensure that the complete system of\nintegrated components ": [],
  "6 Acceptance Testing\nAcceptance testing is a conventional test level and is used to determine whether the complete system\nis acceptable to the customer": [],
  "5 Documenting an AI Component\nThe typical content for the documentation of an AI component includes": [],
  "6 Testing for Concept Drift\nThe operational environment can change over time without the trained model changing\ncorrespondingly": [],
  "7 Selecting a Test Approach for an ML System\nAn AI": [],
  "2 Explain the challenges in testing created by the self": [],
  "2 Describe how autonomous AI": [],
  "2 Explain how to test for bias in an AI": [],
  "2 Explain the challenges in testing created by the probabilistic and non": [],
  "2 Explain the challenges in testing created by the complexity of AI": [],
  "2 Describe how the transparency": [],
  "2 Use a tool to show how explainability can be used by testers": [],
  "2 Explain the challenges in creating test oracles resulting from the specific\ncharacteristics of AI": [],
  "8 Test Objectives and Acceptance Criteria\nAI": [],
  "4 Select appropriate test objectives and acceptance criteria for the AI": [],
  "8 Test Objectives and Acceptance Criteria\nTest objectives and acceptance criteria for a system need to be based on the perceived product risks": [],
  "1 Adversarial Attacks and Data Poisoning\nAI": [],
  "2 Explain how the testing of ML systems can help prevent adversarial attacks and data\npoisoning": [],
  "2 Pairwise Testing\nAI": [],
  "2 Explain how pairwise testing is used for AI": [
    "H"
  ],
  "2 Apply pairwise testing to derive and execute test cases for an AI": [],
  "2 Explain how back": [],
  "2 Explain how A": [],
  "5 Metamorphic Testing\nAI": [],
  "3 Apply metamorphic testing for the testing of AI": [],
  "2 Apply metamorphic testing to derive test cases for a given scenario and execute\nthem": [],
  "2 Explain how experience": [],
  "2 Apply exploratory testing to an AI": [],
  "4 For a given scenario": [],
  "1 Adversarial Attacks and Data Poisoning\n": [],
  "1 Adversarial Attacks\nAn adversarial attack is where an attacker subtly perturbs valid inputs that are passed to the trained\nmodel to cause it to provide incorrect predictions": [],
  "2 Data Poisoning\nData poisoning attacks are where an attacker manipulates the training data to achieve one of two\nresults": [],
  "2 Pairwise Testing\nThe number of parameters of interest for an AI": [],
  "5. Whenever the system\nis updated": [],
  "1998. It differs from traditional test techniques\nin that the expected results of the follow": [],
  "1. Feature expectations are captured in a schema": [],
  "2. All features are beneficial": [],
  "3. No feature": [],
  "4. Features adhere to metalevel requirements": [],
  "5. The data pipeline has appropriate privacy controls": [],
  "6. New features can be added quickly": [],
  "7. All input feature code is tested": [],
  "1. Model specs are reviewed and submitted": [],
  "2. Offline and online metrics correlate": [],
  "3. All hyperparameters have been tuned": [],
  "4. The impact of model staleness is known": [],
  "5. A simpler model is not better": [],
  "6. Model quality is sufficient on important data slices": [],
  "7. The model is tested for considerations of inclusion": [],
  "1. Training is reproducible": [],
  "2. Model specs are unit tested": [],
  "3. The ML pipeline is integration tested": [],
  "4. Model quality is validated before serving": [],
  "5. The model is debuggable": [],
  "6. Models are canaried before serving": [],
  "7. Serving models can be rolled back\nMonitoring Tests": [],
  "1. Dependency changes result in notification": [],
  "2. Data invariants hold for inputs": [],
  "3. Training and serving are not skewed": [],
  "4. Models are not too stale": [],
  "5. Models are numerically stable": [],
  "6. Computing performance has not regressed": [],
  "7. Prediction quality has not regressed": [],
  "2 Describe the main factors that differentiate the test environments for AI": [],
  "2 Describe the benefits provided by virtual test environments in the testing of AI": [],
  "1 AI Technologies for Testing\nAI": [],
  "2 Categorize the AI technologies used in software testing": [],
  "2 Discuss": [],
  "2 Using AI to Analyze Reported Defects\nAI": [],
  "2 Explain how AI can assist in supporting the analysis of new defects": [],
  "3 Using AI for Test Case Generation\nAI": [],
  "2 Explain how AI can assist in test case generation": [],
  "4 Using AI for the Optimization of Regression Test Suites\nAI": [],
  "2 Explain how AI can assist in optimization of regression test suites\n": [],
  "5 Using AI for Defect Prediction\nAI": [],
  "2 Explain how AI can assist in defect prediction": [],
  "2 Implement a simple AI": [],
  "6 Using AI for Testing User Interfaces\nAI": [],
  "2 Explain the use of AI in testing user interfaces\nv": [],
  "1 AI Technologies for Testing\nSeveral AI technologies are listed in Section": [],
  "2 Using AI to Analyze Reported Defects\nReported defects are usually categorized": [],
  "3 Using AI for Test Case Generation\nThe use of AI to generate tests can be a very effective technique for quickly create testing assets and\nmaximizing coverage ": [],
  "4 Using AI for the Optimization of Regression Test Suites\nAs changes are made to a system": [],
  "5 Using AI for Defect Prediction\nDefect prediction can be used to predict whether a defect is present": [],
  "6 Using AI for Testing User Interfaces\n": [],
  "2 Using AI to Test the GUI\nML models can be used to determine the acceptability of user interface screens ": [],
  "12 References\n": [],
  "1 Standards\n": [],
  "11 Guidelines on the testing of AI": [],
  "2 ISTQB Documents\n": [],
  "3 Books and Articles\n": [],
  "679 OF THE EUROPEAN PARLIAMENT AND OF THE\nCOUNCIL on the protection of natural persons with regard to the processing of\npersonal data and on the free movement of such data": [],
  "20 Ministerial Statement on Trade and Digital Economy": [],
  "2019 DES": [],
  "1. Edition": [],
  "6. IEEE": [],
  "2008 Nagappan et al": [],
  "4 Other References\nThe following references point to information available on the Internet": [],
  "1\nAI that exhibits intelligent behaviour comparable to a human across the\nfull range of cognitive abilities ": [],
  "15 Index\nA": [],
  "76\nAPI testing ": [],
  "55\nML algorithms ": [],
  "55\nML functional performance criteria ": [],
  "63\nML functional performance metrics ": [],
  "77 ML model ": [],
  "41 ML model testing ": [],
  "84 ML workflow ": []
}